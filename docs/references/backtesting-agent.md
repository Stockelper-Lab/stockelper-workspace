### ì£¼ê°€ ë°ì´í„° ì ì¬

- yfinanceë¡œ ì ì¬ ë˜ì§€ ì•Šì€ ìµœì‹  ì£¼ê°€ ì¢…ëª©ë“¤ KRX ì´ìš©í•´ ì ì¬ ì™„ë£Œ (148ê°œ ì¢…ëª©)

## ë°±í…ŒìŠ¤íŒ… ì„¤ê³„

### ë ˆí¼ëŸ°ìŠ¤ ì°¸ê³ 

| **í”Œë«í¼** | URL | **ì£¼ë ¥ ë¶„ì•¼** |
| --- | --- | --- |
| **í€€í„°ìŠ¤** | https://www.quantus.kr/foundry | íŒ©í„° íˆ¬ì, ì¬ë¬´ ë¶„ì„ |
| **ì  í¬íŠ¸** | https://genport.newsystock.com/backtest/BackTest.aspx | ìë™ë§¤ë§¤, ê¸°ìˆ ì  ë¶„ì„ |
| **í€€íŠ¸í‚¹** | https://quantking.net/ | ë°ì´í„° ë¶„ì„, ì†Œí˜•ì£¼ |
- í€€í„°ìŠ¤
- ì  í¬íŠ¸
    
    [[íŠ¸ë ˆì´ë”©] ë°±í…ŒìŠ¤íŠ¸](https://www.notion.so/c5a302137ec84490a3e5d2f2e23e0818?pvs=21) 
    
- í€€íŠ¸í‚¹
    
    ![image.png](attachment:dc8d3b09-0b6c-4f57-bbb3-128c8301fb5d:image.png)
    

### Input/Output

Input

- ì£¼ì‹ ìœ ë‹ˆë²„ìŠ¤ : ì½”ìŠ¤í”¼ ì¤‘ëŒ€í˜•, ì½”ìŠ¤í”¼ ì¤‘ì†Œí˜•, ì½”ìŠ¤ë‹¥ ëŒ€í˜•, ì½”ìŠ¤ë‹¥ ì¤‘í˜•, ì½”ìŠ¤ë‹¥ ì†Œí˜•, ì½”ìŠ¤ë‹¥ ì´ˆì†Œí˜•
- ì—…ì¢…
- ì¢…ëª© í•„í„° : í•´ë‹¹ íŒ©í„° ìƒìœ„/í•˜ìœ„ %, ê°’ ê¸°ì¤€
- ì¢…ëª© ì •ë ¬ : ì •ë ¬ ê¸°ì¤€.
    - ëª¨ë©˜í…€, ê°€ê²©, ì¢…í•©ì ìˆ˜, í€ë”ë©˜íƒˆ ë“±
    - **ì´ë²¤íŠ¸ ê°ì„± ì ìˆ˜, ì´ë²¤íŠ¸ íƒ€ì…**
- íˆ¬ìê¸ˆì•¡
- ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°
- ìµœëŒ€ ë³´ìœ  ì¢…ëª© ìˆ˜
- í¬íŠ¸í´ë¦¬ì˜¤ ìµœëŒ€ ì¢…ëª© ìˆ˜
- íˆ¬ì ì‹œì‘ì¼ - íˆ¬ì ì¢…ë£Œì¼
- ìˆ˜ìˆ˜ë£Œìœ¨, ìŠ¬ë¦¬í”¼ì§€
- ì£¼ê°€ì •ë³´

Output

- ì„±ê³¼ ì§€í‘œ : ëˆ„ì  ìˆ˜ìµë¥ , MDD, ì´ ì†ìµ ë“±
- ê±°ë˜ ë‚´ì—­ : ì¼ìë³„ ë§¤ë§¤ ì¢…ëª©
    - ë§¤ë§¤ ìˆ˜ëŸ‰, ê¸ˆì•¡, ë§¤ë§¤ ì‚¬ìœ  ë“±
- ë¦¬í¬íŠ¸ ìƒì„± (LLM ê¸°ë°˜)
    - ì„±ê³¼ì§€í‘œì™€ ê±°ë˜ë‚´ì—­ ê¸°ë°˜ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¦¬í¬íŠ¸ + ì–´ë–¤ ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆì„ ë•Œ ìˆ˜ìµë¥ ì´ ê°€ì¥ ì¢‹ì•˜ëŠ”ì§€

### ë…¼ì˜ì‚¬í•­

- ê°ì„±ë¶„ì„ ì‹¤ì‹œ ì£¼ê¸° : ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì‹œ, **ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì‹œ ë°”ë¡œ ê°ì„±ë¶„ì„ (ëª¨ë“  ì¢…ëª©ì— ëŒ€í•´ 2-3ì‹œê°„ ì£¼ê¸°)**, ì¼ê°„
    - í”„ë¡¬í”„íŠ¸ ì „ë‹¬
- ë°±í…ŒìŠ¤íŒ… ì‹œ í•„ìš”í•œ ì‚¬ìš©ì ì •ë³´ ì •ì˜
    - ì„ íƒ :
    - ê³ ì • :
- ì–´ë””ì„œ ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•˜ëŠ”ì§€
- ì±—ë´‡ vs. ì„œë¹„ìŠ¤
    - ê±¸ë¦¬ëŠ” ì‹œê°„ ì²´í¬ í•„ìš”
    - ìœ ì € ê²½í—˜, íš¨ìœ¨ì„± ê³ ë ¤í•´ì•¼ í•´ì„œ ì¢€ ë” ê³ ë¯¼ í•„ìš”
- ì£¼ê°€ ì ì¬  ì½”ë“œ
    - í˜ì°¬ë‹˜ê»˜ ì „ë‹¬

## ì•¡ì…˜ ì•„ì´í…œ

- [ ]  ë°±í…ŒìŠ¤íŒ… ì—ì´ì „íŠ¸ êµ¬í˜„
- [x]  í”„ë¡¬í”„íŠ¸ ì „ë‹¬
- [x]  ì£¼ê°€ì ì¬ ì½”ë“œ ì „ë‹¬

### ê°ì„±ë¶„ì„ í”„ë¡¬í”„íŠ¸

```jsx
NEWS_SENTIMENT_SYSTEM_PROMPT = """You are a financial news sentiment analysis expert specializing in Korean stock market news.
Analyze the given Korean news title and body to evaluate its impact on the stock market,
and calculate a sentiment score between -1 (very negative) and 1 (very positive).

Analysis considerations:
1. The news content is in Korean. Comprehensively analyze both the Korean title and body of the news.
2. Positive factors affecting stock price: earnings improvement (ì‹¤ì  ê°œì„ ), new contracts (ì‹ ê·œ ê³„ì•½), technological innovation (ê¸°ìˆ  í˜ì‹ ), positive outlook (ê¸ì •ì  ì „ë§), etc.
3. Negative factors affecting stock price: earnings deterioration (ì‹¤ì  ì•…í™”), increased risks (ë¦¬ìŠ¤í¬ ì¦ê°€), negative outlook (ë¶€ì •ì  ì „ë§), regulatory tightening (ê·œì œ ê°•í™”), etc.
4. Neutral news should be evaluated close to 0
5. Extract the Korean company name mentioned in the news (for knowledge graph relationship creation). Return the company name exactly as it appears in Korean.
6. You MUST always classify the news into an event type. Analyze the Korean news content and identify the primary event category that best describes the news. If multiple events are mentioned, select the most significant one. Use a descriptive event type name in lowercase with underscores (e.g., "earnings", "share_buyback", "dividend", "merger_acquisition", "new_contract", "regulatory", "product_launch", "management_change", "general", etc.). You can use any appropriate event type name that accurately describes the news content.

Output must be in JSON format only."""

NEWS_SENTIMENT_USER_PROMPT = """Analyze the sentiment of the following Korean news article.

News information:
- Title: {title}
- Body: {body}
- Date: {date}

Output only in the following JSON format (no other explanation, JSON only):
{{
    "sentiment_score": <float>,  // Real number between -1.0 (very negative) and 1.0 (very positive)
    "event_type": "<string>",  // REQUIRED: Event category that best describes the news. Use a descriptive name in lowercase with underscores. Examples include: "earnings", "share_buyback", "dividend", "merger_acquisition", "new_contract", "regulatory", "product_launch", "management_change", "general", "partnership", "investment", "lawsuit", "ipo", etc. If multiple events exist, select the most significant one. Never use "none" or null.
    "company": "<company_name>"  // Korean company name mentioned in the news (return exactly as it appears in Korean, null if not mentioned)
}}

Notes:
- The news content is in Korean. Analyze the Korean text carefully.
- sentiment_score must be a real number between -1.0 and 1.0.
- event_type is REQUIRED and must always be a descriptive string in lowercase with underscores. Examples include but are not limited to: "earnings", "share_buyback", "dividend", "merger_acquisition", "new_contract", "regulatory", "product_launch", "management_change", "general", "partnership", "investment", "lawsuit", "ipo", "stock_split", "bankruptcy", etc. Never use "none" or null. If multiple events are mentioned, select the most important/primary one.
- company must be the Korean company name exactly as it appears in the news (e.g., "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"). Use null if no company is mentioned.
- Output JSON format only, no additional explanation or markdown formatting."""

```

### ì£¼ê°€ ì ì¬ ì½”ë“œ

```python
import FinanceDataReader as fdr
import pandas as pd
from tqdm import tqdm
from datetime import datetime
from sqlalchemy import create_engine, text
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename='stock_chatbot/stockelper-llm/src/multi_agent/store_daily_stock_price.log')
logger = logging.getLogger(__name__)

# ----------------------------------------------------------
# ì„¤ì •
# ----------------------------------------------------------
db_user = "stockelper"
db_password = 
db_host = 
db_port = 
db_name = "postgres"
table_name = "daily_stock_price"

engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')

with engine.connect() as conn:
    current_db = conn.execute(text("SELECT current_database();")).fetchone()[0]
    logger.info(f"Current database: {current_db}")
    if current_db != db_name:
        conn.execute(text(f"CREATE DATABASE {db_name};"))
        conn.commit()
    else:
        logger.info(f"Database {db_name} already exists")

with engine.connect() as conn:
    conn.execute(text("""
        ALTER TABLE daily_stock_price 
        ALTER COLUMN open TYPE NUMERIC(15, 2),
        ALTER COLUMN high TYPE NUMERIC(15, 2),
        ALTER COLUMN low TYPE NUMERIC(15, 2),
        ALTER COLUMN close TYPE NUMERIC(15, 2),
        ALTER COLUMN adj_close TYPE NUMERIC(20, 6);
    """))
    conn.commit()

# í…Œì´ë¸” ìƒì„± í•¨ìˆ˜
def create_table_if_not_exists(engine):
    with engine.connect() as conn:
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS daily_stock_price (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(10) NOT NULL,
                date DATE NOT NULL,
                open NUMERIC(12, 2),
                high NUMERIC(12, 2),
                low NUMERIC(12, 2),
                close NUMERIC(12, 2),
                volume BIGINT,
                adj_close NUMERIC(12, 6),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, date)
            );
            
            CREATE INDEX IF NOT EXISTS idx_symbol_date ON daily_stock_price(symbol, date);
            CREATE INDEX IF NOT EXISTS idx_date ON daily_stock_price(date);
        """))
        conn.commit()

# ë°°ì¹˜ UPSERT í•¨ìˆ˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ìš©)
def bulk_upsert(engine, df, table_name, batch_size=10000):
    """
    ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ UPSERT ìˆ˜í–‰
    """
    temp_table = f"{table_name}_temp_{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}"
    
    try:
        # 1. ì„ì‹œ í…Œì´ë¸”ì— DataFrame ì „ì²´ë¥¼ í•œ ë²ˆì— ì‚½ì… 
        df.to_sql(temp_table, engine, if_exists='replace', index=False, method='multi')
        
        # 2. í•œ ë²ˆì˜ SQL ì¿¼ë¦¬ë¡œ ëª¨ë“  ë°ì´í„° UPSERT 
        logger.info(f"   ğŸ”„ UPSERT ì‹¤í–‰ ì¤‘...")
        with engine.begin() as conn:  # ìë™ ì»¤ë°‹
            conn.execute(text(f"""
                INSERT INTO {table_name} (symbol, date, open, high, low, close, volume, adj_close)
                SELECT symbol, date, open, high, low, close, volume, adj_close
                FROM {temp_table}
                ON CONFLICT (symbol, date) 
                DO UPDATE SET
                    open = EXCLUDED.open,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    close = EXCLUDED.close,
                    volume = EXCLUDED.volume,
                    adj_close = EXCLUDED.adj_close
            """))
        
        # 3. ì„ì‹œ í…Œì´ë¸” ì‚­ì œ
        with engine.connect() as conn:
            conn.execute(text(f"DROP TABLE IF EXISTS {temp_table};"))
            conn.commit()
            
        logger.info(f"   âœ… {len(df):,}í–‰ ì²˜ë¦¬ ì™„ë£Œ!")
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì„ì‹œ í…Œì´ë¸” ì •ë¦¬
        try:
            with engine.connect() as conn:
                conn.execute(text(f"DROP TABLE IF EXISTS {temp_table};"))
                conn.commit()
        except:
            pass
        raise e

def report_ingestion_status(engine, all_symbols):
    """
    DBì— ì ì¬ëœ ì¢…ëª© ìˆ˜ì™€ ì „ì²´ ì¢…ëª© ìˆ˜ë¥¼ ë¹„êµí•´ ë¦¬í¬íŠ¸
    """
    total_symbols = len(all_symbols)
    with engine.connect() as conn:
        ingested_symbols = [
            row[0]
            for row in conn.execute(
                text("SELECT DISTINCT symbol FROM daily_stock_price")
            )
        ]
        ingested_count = len(ingested_symbols)
        ingested_set = set(ingested_symbols)
        missing_symbols = [sym for sym in all_symbols if sym not in ingested_set]

    coverage = (
        (ingested_count / total_symbols) * 100 if total_symbols > 0 else 0
    )
    logger.info("===== DB ì ì¬ í˜„í™© =====")
    logger.info(f"ì „ì²´ ìƒì¥ ì¢…ëª© ìˆ˜: {total_symbols:,}")
    logger.info(f"ì ì¬ ì™„ë£Œ ì¢…ëª© ìˆ˜: {ingested_count:,} ({coverage:.2f}%)")
    if missing_symbols:
        logger.info(f"ë¯¸ì ì¬ ì¢…ëª© ìˆ˜: {len(missing_symbols):,}")
        logger.info(f"ì˜ˆì‹œ ë¯¸ì ì¬ ì¢…ëª©: {missing_symbols[:10]}")
    else:
        logger.info("ëª¨ë“  ì¢…ëª©ì´ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return missing_symbols

# ----------------------------------------------------------
# 1ï¸âƒ£ KRX ìƒì¥ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
krx = fdr.StockListing("KRX")
symbols = krx['Code'].tolist()
logger.info(f"KRX ìƒì¥ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ: {len(symbols)}ê°œ")

target_symbols = [symbols[1]]
from_date = '2005-01-01'
to_date = datetime.now().strftime('%Y-%m-%d')

# í…Œì´ë¸” ìƒì„±
create_table_if_not_exists(engine)

missing_symbols = report_ingestion_status(engine, symbols)

# ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
for sym in tqdm(missing_symbols, desc="ë°ì´í„° ìˆ˜ì§‘"):
    try:
        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        krx_df = fdr.DataReader(f'KRX:{sym}', start=from_date, end=to_date)
        yh_df = fdr.DataReader(f'YAHOO:{sym}.KS', start=from_date, end=to_date)

        # ë°ì´í„° ë³‘í•©
        df = yh_df.merge(krx_df, left_index=True, right_index=True, suffixes=('', '_krx'), how='outer')
        df[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']] = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']].bfill()
        df.dropna(inplace=True)
        df = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']]

    except Exception as e:
        if 'Not Found for url' in str(e):
            df = krx_df.copy()[['Open', 'High', 'Low', 'Close', 'Volume']]
            df['Adj Close'] = df['Close']
        else:
            raise e
        
        df.index.name = 'Date'
        df.reset_index(inplace=True)
        
        # ì‹¬ë³¼ ì¶”ê°€
        df['symbol'] = sym
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df = df.rename(columns={
            'Open': 'open',
            'High': 'high',
            'Low': 'low',
            'Close': 'close',
            'Volume': 'volume',
            'Adj Close': 'adj_close',
            'Date': 'date'
        })
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        df = df[['symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'adj_close']]
        
        # ë°°ì¹˜ UPSERT ì‹¤í–‰
        bulk_upsert(engine, df, table_name)        
        logger.info(f"âœ… {sym} ì €ì¥ ì™„ë£Œ ({len(df):,} rows)")
        
    except Exception as e:
        logger.error(f"âŒ {sym} ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        continue

logger.info(f"\nëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
# missing_symbols = report_ingestion_status(engine, symbols)

```

# í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ…

---

## ì‹œìŠ¤í…œ êµ¬ì¡°

```python
portfolio_backtest.py
â”œâ”€â”€ BacktestInput: ì…ë ¥ íŒŒë¼ë¯¸í„° ì •ì˜
â”œâ”€â”€ BacktestOutput: ì¶œë ¥ ê²°ê³¼ êµ¬ì¡°
â”œâ”€â”€ generate_synthetic_sentiment_data(): ì„ì˜ ê°ì„± ë°ì´í„° ìƒì„±
â”œâ”€â”€ DataLoader: DB ë°ì´í„° ì¡°íšŒ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ get_stock_price_data(): PostgreSQLì—ì„œ ì£¼ê°€ ì¡°íšŒ
â”‚   â””â”€â”€ get_news_sentiment_data(): 
â”œâ”€â”€ PortfolioStrategy: ë°±í…ŒìŠ¤íŒ… ì „ëµ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ rebalance(): í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±
â”‚   â””â”€â”€ manage_position(): ê°œë³„ í¬ì§€ì…˜ ê´€ë¦¬
â””â”€â”€ run_backtest(): ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
```

---

## Input íŒŒë¼ë¯¸í„°

### BacktestInput í´ë˜ìŠ¤

ë°±í…ŒìŠ¤íŒ…ì— í•„ìš”í•œ ëª¨ë“  ì…ë ¥ íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤

```python
class BacktestInput:
    """
    ë°±í…ŒìŠ¤íŒ… ì…ë ¥ íŒŒë¼ë¯¸í„° í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ë°±í…ŒìŠ¤íŒ…ì— í•„ìš”í•œ ëª¨ë“  ì…ë ¥ íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    ìœ ë‹ˆë²„ìŠ¤, í•„í„°, ì •ë ¬ ê¸°ì¤€, íˆ¬ì íŒŒë¼ë¯¸í„° ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
    """
    # ì£¼ì‹ ìœ ë‹ˆë²„ìŠ¤: íˆ¬ì ëŒ€ìƒì´ ë˜ëŠ” ì‹œì¥ êµ¬ë¶„
    # ì˜ˆ: ì½”ìŠ¤í”¼ ì¤‘ëŒ€í˜•, ì½”ìŠ¤ë‹¥ ëŒ€í˜• ë“±
    universe: List[str] = field(default_factory=lambda: [
        "ì½”ìŠ¤í”¼ ì¤‘ëŒ€í˜•", "ì½”ìŠ¤í”¼ ì¤‘ì†Œí˜•", "ì½”ìŠ¤ë‹¥ ëŒ€í˜•", 
        "ì½”ìŠ¤ë‹¥ ì¤‘í˜•", "ì½”ìŠ¤ë‹¥ ì†Œí˜•", "ì½”ìŠ¤ë‹¥ ì´ˆì†Œí˜•"
    ])
    
    # ì—…ì¢… í•„í„°: íŠ¹ì • ì—…ì¢…ë§Œ ì„ íƒ (Noneì´ë©´ ëª¨ë“  ì—…ì¢…)
    sectors: Optional[List[str]] = None
    
    # ì¢…ëª© í•„í„° ì„¤ì •
    filter_type: Optional[str] = None  # "top": ìƒìœ„, "bottom": í•˜ìœ„, "value": ê°’ ê¸°ì¤€
    filter_percent: Optional[float] = None  # ìƒìœ„/í•˜ìœ„ % (ì˜ˆ: 20 = ìƒìœ„ 20%)
    filter_value: Optional[float] = None  # ê°’ ê¸°ì¤€ í•„í„°ë§
    
    # ì¢…ëª© ì •ë ¬ ê¸°ì¤€
    # "momentum": ëª¨ë©˜í…€, "price": ê°€ê²©, "composite_score": ì¢…í•©ì ìˆ˜,
    # "fundamental": í€ë”ë©˜íƒˆ, "sentiment_score": ê°ì„± ì ìˆ˜, "event_type": ì´ë²¤íŠ¸ íƒ€ì…
    sort_by: str = "sentiment_score"
    sort_ascending: bool = False  # False: ë‚´ë¦¼ì°¨ìˆœ(ë†’ì€ ìˆœ), True: ì˜¤ë¦„ì°¨ìˆœ
    
    # íˆ¬ì íŒŒë¼ë¯¸í„°
    initial_cash: float = 100_000_000  # ì´ˆê¸° íˆ¬ìê¸ˆì•¡ (1ì–µì›)
    rebalancing_period: str = "monthly"  # ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°: "daily", "weekly", "monthly", "quarterly"
    max_positions: int = 10  # ìµœëŒ€ ë³´ìœ  ì¢…ëª© ìˆ˜
    max_portfolio_size: int = 20  # í¬íŠ¸í´ë¦¬ì˜¤ ìµœëŒ€ ì¢…ëª© ìˆ˜ (ì„ íƒ ëŒ€ìƒ)
    
    # ë°±í…ŒìŠ¤íŒ… ê¸°ê°„
    start_date: str = "2024-01-01"
    end_date: str = "2024-12-31"
    
    # ê±°ë˜ ë¹„ìš©
    commission_rate: float = 0.0005  # ê±°ë˜ ìˆ˜ìˆ˜ë£Œìœ¨ (0.05%)
    slippage_rate: float = 0.001  # ìŠ¬ë¦¬í”¼ì§€ìœ¨ (0.1%)
    
    # DB ì—°ê²° ì„¤ì •
    db_user: str = "stockelper"
    db_password: str = 
    db_host: str = 
    db_port: str = "21002"
    db_name: str = "postgres"
    
    # MongoDB ì„¤ì • (ë‰´ìŠ¤ ê°ì„± ë°ì´í„° - ì„ íƒì‚¬í•­)
    mongo_uri: Optional[str] = None  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´, ì—†ìœ¼ë©´ ì„ì˜ ìƒì„±

```

**1. ì£¼ì‹ ìœ ë‹ˆë²„ìŠ¤ ì„¤ì •**

- **ì„¤ëª…**: íˆ¬ì ëŒ€ìƒì´ ë˜ëŠ” ì‹œì¥ êµ¬ë¶„
- **ê¸°ë³¸ê°’**: ëª¨ë“  ìœ ë‹ˆë²„ìŠ¤ í¬í•¨
- **ì˜ˆì‹œ**:Â [        "ì½”ìŠ¤í”¼ ì¤‘ëŒ€í˜•", "ì½”ìŠ¤í”¼ ì¤‘ì†Œí˜•", "ì½”ìŠ¤ë‹¥ ëŒ€í˜•", 
        "ì½”ìŠ¤ë‹¥ ì¤‘í˜•", "ì½”ìŠ¤ë‹¥ ì†Œí˜•", "ì½”ìŠ¤ë‹¥ ì´ˆì†Œí˜•"]
- í•„í„°ë§ ë¡œì§ êµ¬í˜„ í•„ìš”!

**2. ì—…ì¢… í•„í„°**

sectors:Â Optional[List[str]]Â =Â None

- **ì„¤ëª…**: íŠ¹ì • ì—…ì¢…ë§Œ ì„ íƒ (Noneì´ë©´ ëª¨ë“  ì—…ì¢…)
- **ì˜ˆì‹œ**:Â ["ë°˜ë„ì²´", "ë°”ì´ì˜¤"]

**3. ì¢…ëª© í•„í„°**

filter_type:Â Optional[str]Â =Â NoneÂ Â *#Â "top",Â "bottom",Â "value"*

filter_percent:Â Optional[float]Â =Â NoneÂ Â *#Â ìƒìœ„/í•˜ìœ„Â %*

filter_value:Â Optional[float]Â =Â NoneÂ Â *#Â ê°’Â ê¸°ì¤€*

**4. ì¢…ëª© ì •ë ¬ ê¸°ì¤€**

sort_by:Â strÂ =Â "sentiment_score" # momentum, price, composite_score, fundamental, 

sort_ascending:Â boolÂ =Â False

- **sort_by**: ì •ë ¬ ê¸°ì¤€ (êµ¬í˜„ í•„ìš”)
    - "momentum": ëª¨ë©˜í…€
    - "price": ê°€ê²©
    - "composite_score": ì¢…í•©ì ìˆ˜
    - "fundamental": í€ë”ë©˜íƒˆ
    - "sentiment_score":Â **ê°ì„± ì ìˆ˜**Â (ê¸°ë³¸ê°’)
    - "event_type": ì´ë²¤íŠ¸ íƒ€ì…
- **sort_ascending**:Â FalseÂ = ë‚´ë¦¼ì°¨ìˆœ (ë†’ì€ ìˆœ),Â TrueÂ = ì˜¤ë¦„ì°¨ìˆœ

**5. íˆ¬ì íŒŒë¼ë¯¸í„°**

initial_cash:Â floatÂ =Â 100_000_000Â Â *#Â ì´ˆê¸°Â íˆ¬ìê¸ˆì•¡Â (1ì–µì›)*

rebalancing_period:Â strÂ =Â "monthly"Â Â *#Â ë¦¬ë°¸ëŸ°ì‹±Â ì£¼ê¸° : daily, weekly, monthly, quarterly*

max_positions:Â intÂ =Â 10Â Â *#Â ìµœëŒ€Â ë³´ìœ Â ì¢…ëª©Â ìˆ˜*

max_portfolio_size:Â intÂ =Â 20Â Â *#Â í¬íŠ¸í´ë¦¬ì˜¤Â ìµœëŒ€Â ì¢…ëª©Â ìˆ˜*

**6. ë°±í…ŒìŠ¤íŒ… ê¸°ê°„**

start_date:Â strÂ =Â "2024-01-01"

end_date:Â strÂ =Â "2024-12-31"

- **í˜•ì‹**:Â "YYYY-MM-DD"

**7. ê±°ë˜ ë¹„ìš©**

commission_rate:Â floatÂ =Â 0.0005Â Â *#Â 0.05%*

slippage_rate:Â floatÂ =Â 0.001Â Â *#Â 0.1%*

- **commission_rate**: ê±°ë˜ ìˆ˜ìˆ˜ë£Œìœ¨
- **slippage_rate**: ìŠ¬ë¦¬í”¼ì§€ìœ¨ (ì²´ê²° ê°€ê²©ê³¼ ì£¼ë¬¸ ê°€ê²©ì˜ ì°¨ì´)

**8. DB ì—°ê²°Â ì„¤ì •**

- DB ì—°ê²° ì •ë³´

## **Output ê²°ê³¼**

**BacktestOutput í´ë˜ìŠ¤**

**1. ì„±ê³¼ ì§€í‘œ**

```python
cumulative_return:Â floatÂ Â *#Â ëˆ„ì Â ìˆ˜ìµë¥ Â (ì†Œìˆ˜)*
total_return:Â floatÂ Â Â Â Â Â Â *#Â ì´Â ìˆ˜ìµë¥ Â (%)*
annualized_return:Â floatÂ Â *#Â ì—°í™˜ì‚°Â ìˆ˜ìµë¥ Â (%)*
mdd:Â floatÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â *#Â MaximumÂ DrawdownÂ (ìµœëŒ€Â ë‚™í­,Â %)*
sharpe_ratio:Â floatÂ Â Â Â Â Â *#Â ìƒ¤í”„Â ì§€ìˆ˜*
win_rate:Â floatÂ Â Â Â Â Â Â Â Â Â *#Â ìŠ¹ë¥ Â (%)*
total_trades:Â intÂ Â Â Â Â Â Â Â *#Â ì´Â ê±°ë˜Â íšŸìˆ˜*
total_profit:Â floatÂ Â Â Â Â Â *#Â ì´Â ìˆ˜ìµÂ (ì›)*
total_loss:Â floatÂ Â Â Â Â Â Â Â *#Â ì´Â ì†ì‹¤Â (ì›)*
```

**2. ê±°ë˜ ë‚´ì—­**

trades:Â List[Dict]

ê° ê±°ë˜ëŠ” ë‹¤ìŒÂ ì •ë³´ë¥¼ í¬í•¨

{

'date':Â '2024-01-15',Â Â Â Â Â Â *#Â ê±°ë˜Â ì¼ì*

'symbol':Â '005930',Â Â Â Â Â Â Â Â Â *#Â ì¢…ëª©Â ì½”ë“œ*

'action':Â 'BUY',Â Â Â Â Â Â Â Â Â Â Â Â *#Â ë§¤ë§¤Â í–‰ìœ„Â (BUY/SELL)*

'size':Â 100,Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â *#Â ê±°ë˜Â ìˆ˜ëŸ‰*

'price':Â 75000.0,Â Â Â Â Â Â Â Â Â Â Â *#Â ê±°ë˜Â ê°€ê²©*

'amount':Â 7500000.0,Â Â Â Â Â Â Â *#Â ê±°ë˜Â ê¸ˆì•¡*

'reason':Â 'ê°ì„±ì ìˆ˜:Â 0.75'Â Â *#Â ë§¤ë§¤Â ì‚¬ìœ *

}

**3. ë¦¬í¬íŠ¸**

report:Â str

- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¦¬í¬íŠ¸
- ì‹¤í–‰ ì •ë³´, ì„±ê³¼ ì§€í‘œ, ì†ìµ ë¶„ì„, ì´ë²¤íŠ¸ë³„ ì„±ê³¼, ê±°ë˜ ë‚´ì—­ í¬í•¨

**4. ì´ë²¤íŠ¸ë³„ ìˆ˜ìµë¥  ë¶„ì„**

event_performance:Â Dict[str,Â Dict]

ê° ì´ë²¤íŠ¸ íƒ€ì…ë³„ í†µê³„:

{

'earnings':Â {

'count':Â 10,Â Â Â Â Â Â Â Â Â Â Â *#Â ê±°ë˜Â íšŸìˆ˜*

'total_profit':Â 1000000,Â *#Â ì´Â ìˆ˜ìµ*

'total_loss':Â 500000,Â Â Â *#Â ì´Â ì†ì‹¤*

'win_count':Â 7,Â Â Â Â Â Â Â Â Â *#Â ìˆ˜ìµÂ ê±°ë˜Â ìˆ˜*

'loss_count':Â 3Â Â Â Â Â Â Â Â Â *#Â ì†ì‹¤Â ê±°ë˜Â ìˆ˜*

},

'share_buyback':Â {...},

'general':Â {...}

}

## **PortfolioStrategy ì „ëµ**

### 1. ë¦¬ë°¸ëŸ°ì‹± ë©”ì»¤ë‹ˆì¦˜

- ì •ê¸°ì ìœ¼ë¡œ(ë§¤ì›”/ë§¤ì£¼ ë“±) í¬íŠ¸í´ë¦¬ì˜¤ ì¬êµ¬ì„±
- í˜„ì¬ ë³´ìœ  ì¢…ëª©ì„ ëª¨ë‘ ì²­ì‚°í•˜ê³  ìƒˆë¡œìš´ ì¢…ëª© ì„ íƒ
- ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°:Â rebalancing_periodÂ íŒŒë¼ë¯¸í„°ë¡œ ì„¤ì •

### 2. ì¢…ëª© ì„ íƒ ë¡œì§

ê°ì„±Â ì ìˆ˜Â >=Â sentiment_buy_thÂ (ê¸°ë³¸ê°’:Â 0.3)Â â†’Â ë§¤ìˆ˜ê°ì„±Â ì ìˆ˜Â <=Â sentiment_sell_thÂ (ê¸°ë³¸ê°’:Â -0.4)Â â†’Â ì¦‰ì‹œÂ ì²­ì‚°

- ê°ì„± ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ì¢…ëª©ë§Œ ë§¤ìˆ˜
- ìµœëŒ€ ë³´ìœ  ì¢…ëª© ìˆ˜ ì œí•œ (max_positions)

### 3. í¬ì§€ì…˜ ê´€ë¦¬

- ë¶€ì •ì  ê°ì„± ì²´í¬: ê°ì„± ì ìˆ˜ê°€Â sentiment_sell_thÂ ì´í•˜ì´ë©´ ì¦‰ì‹œ ì²­ì‚°
- ATR ê¸°ë°˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬:
- ìŠ¤íƒ‘ë¡œìŠ¤: í˜„ì¬ê°€ - 2Ã—ATR
- ì´ìµì‹¤í˜„: í˜„ì¬ê°€ + 3Ã—ATR
- ê° ì¢…ëª©ë³„ ë…ë¦½ì ì¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬

### 4. ê¸°ìˆ ì  ì§€í‘œ í™œìš©

- SMA(ì´ë™í‰ê· ì„ ): ë‹¨ê¸°(10ì¼), ì¥ê¸°(30ì¼) ì´ë™í‰ê· ìœ¼ë¡œ ì¶”ì„¸ íŒŒì•…
- ATR(í‰ê·  ì§„í­): ë³€ë™ì„± ì§€í‘œë¡œ ë¦¬ìŠ¤í¬ ê´€ë¦¬

## **ë™ì‘ íë¦„**

1. ë°ì´í„° ë¡œë”©: PostgreSQLì—ì„œ ì£¼ê°€ ë°ì´í„° ì¡°íšŒ
2. ê°ì„± ë°ì´í„° ì²˜ë¦¬: MongoDBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì„ì˜ ìƒì„±
3. ë°ì´í„° ë³‘í•©: ì£¼ê°€ ë°ì´í„°ì™€ ê°ì„± ë°ì´í„°ë¥¼ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
4. ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰: Backtrader ì—”ì§„ìœ¼ë¡œ ì „ëµ ì‹¤í–‰
5. ê²°ê³¼ ë¶„ì„: ì„±ê³¼ ì§€í‘œ, ê±°ë˜ ë‚´ì—­, ì´ë²¤íŠ¸ë³„ ë¶„ì„
6. ë¦¬í¬íŠ¸ ìƒì„±: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¦¬í¬íŠ¸ ìƒì„±

### ì‚¬ìš©ì˜ˆì‹œ

```python
from portfolio_backtest import BacktestInput, run_backtest
import asyncio

# ì„¤ì •
input_params = BacktestInput(
    start_date="2024-01-01",
    end_date="2024-12-31",
    initial_cash=100_000_000,
    rebalancing_period="monthly",
    max_positions=10
)

# ì‹¤í–‰
output = asyncio.run(run_backtest(input_params))

# ê²°ê³¼ í™•ì¸
print(output.report)
```

![image.png](attachment:09f2b307-6d81-4ad5-8e05-7ab817f87a94:image.png)

## ì•ìœ¼ë¡œ TO DO LIST

**í•„í„°ë§ ë¡œì§ êµ¬í˜„ (ë†’ìŒ)**

1. ìœ ë‹ˆë²„ìŠ¤ í•„í„°ë§ êµ¬í˜„ : ì½”ìŠ¤í”¼ ëŒ€í˜•, ì¤‘ì†Œí˜• ë“± 
2. ì¢…ëª© í•„í„°ë§ ë¡œì§ êµ¬í˜„ 
    - filter_typeÂ ê¸°ë°˜ í•„í„°ë§Â (top/bottom/value)
    - filter_percentÂ ê¸°ë°˜ ìƒìœ„/í•˜ìœ„ N% ì„ íƒ
    - filter_valueÂ ê¸°ë°˜ ê°’ ê¸°ì¤€ í•„í„°ë§
    - í•„í„°ë§ ê¸°ì¤€ ì§€í‘œ ê³„ì‚° (ëª¨ë©˜í…€, í€ë”ë©˜íƒˆÂ ë“±)
3. ì¢…ëª© ì •ë ¬Â ë¡œì§ êµ¬í˜„ : í˜„ì¬ëŠ” ê°ì„±ì ìˆ˜ë§Œ êµ¬í˜„ 
    1. ì˜ˆì‹œ 
        - composite_score: ì¢…í•© ì ìˆ˜ ê³„ì‚°Â ë° ì •ë ¬
        - fundamental: í€ë”ë©˜íƒˆ ì§€í‘œ ê¸°ë°˜ ì •ë ¬
        - sentiment_score: ê°ì„± ì ìˆ˜ ê¸°ë°˜Â ì •ë ¬
        - event_type: ì´ë²¤íŠ¸ íƒ€ì… ìš°ì„ ìˆœìœ„ ì •ë ¬
4. ì—…ì¢… í•„í„°ë§ êµ¬í˜„
    1. ì¢…ëª© ì—…ì¢… ì •ë³´ ê°€ì ¸ì™€ì•¼ í•¨ 

**ì „ëµ ê³ ë„í™”**

1. í¬ì§€ì…˜ ì‚¬ì´ì§• ê°œì„  (ë†’ìŒ)
    1. ê· ë“± ë¶„í•  íˆ¬ì(í˜„ì¬) â†’ ê°ì„± ì ìˆ˜ ê¸°ë°˜ / ë¦¬ìŠ¤í¬ ê¸°ë°˜ í¬ì§€ì…˜ ì‚¬ì´ì§•  
2. Â ****ì´ë²¤íŠ¸ ê¸°ë°˜ ë§¤ë§¤Â ë¡œì§ ê°•í™”
    1. ì‹¤ì œ ì´ë²¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° 
    2. ì´ë²¤íŠ¸ë³„ ê°€ì¤‘ì¹˜ ì ìš©
    3. ì´ë²¤íŠ¸ ì¡°í•© ì ìš© 
3. Â ****ë¦¬ë°¸ëŸ°ì‹± ë¡œì§ ê°œì„  
    1. (í˜„ì¬) ëª¨ë“  ì¢…ëª©Â ì²­ì‚° í›„ ì¬ë§¤ìˆ˜ â†’ ë¶€ë¶„ ë¦¬ë°¸ëŸ°ì‹±
4. í€ë”ë©˜íƒˆ ë°ì´í„° í†µí•© (ë†’ìŒ)
    - í˜„ì¬ ìƒíƒœ: ì£¼ê°€Â ë°ì´í„°ë§Œ ì‚¬ìš©
    - êµ¬í˜„ í•„ìš”:
        - ì¬ë¬´ì œí‘œ ë°ì´í„° ì¡°íšŒ ë° í†µí•©
        - PER, PBR,Â ROE ë“± ì§€í‘œ ê³„ì‚°
        - í€ë”ë©˜íƒˆ ê¸°ë°˜ í•„í„°ë§/ì •ë ¬
5. ê¸°ìˆ ì  ì§€í‘œÂ ì¶”ê°€
    - í˜„ì¬ ìƒíƒœ: SMA, ATRë§Œ ì‚¬ìš©
    - ì¶”ê°€ í•„ìš”:
    - RSI, MACD, ë³¼ë¦°ì € ë°´ë“œ ë“±
    - ëª¨ë©˜í…€Â ì§€í‘œ (ROC, Stochastic ë“±)
    - ì¶”ì„¸ ì§€í‘œ (ADX,Â Parabolic SARÂ ë“±)

**ë¶„ì„ ë° ë¦¬í¬íŠ¸**

1. ì„±ê³¼ ì§€í‘œ ì¶”ê°€
2. LLMÂ ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (ë†’ìŒ)
3. ì‹œê°í™” ì¶”ê°€